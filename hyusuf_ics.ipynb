{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzqF85fQNqT-"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxsT7nxxNzBa"
   },
   "outputs": [],
   "source": [
    "# Basic libraries for analysis and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn library for preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Sklearn library for model building\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn_evaluation.plot import grid_search\n",
    "\n",
    "# Ignoring warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SEEXMiVN-qO"
   },
   "source": [
    "# Loading The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ci1qYzQsN8CC"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"triple/data1.csv\")\n",
    "df2 = pd.read_csv(\"triple/data2.csv\")\n",
    "df3 = pd.read_csv(\"triple/data3.csv\")\n",
    "df4 = pd.read_csv(\"triple/data4.csv\")\n",
    "df5 = pd.read_csv(\"triple/data5.csv\")\n",
    "df6 = pd.read_csv(\"triple/data6.csv\")\n",
    "df7 = pd.read_csv(\"triple/data7.csv\")\n",
    "df8 = pd.read_csv(\"triple/data8.csv\")\n",
    "df9 = pd.read_csv(\"triple/data9.csv\")\n",
    "df10 = pd.read_csv(\"triple/data10.csv\")\n",
    "df11 = pd.read_csv(\"triple/data11.csv\")\n",
    "df12 = pd.read_csv(\"triple/data12.csv\")\n",
    "df13 = pd.read_csv(\"triple/data13.csv\")\n",
    "df14 = pd.read_csv(\"triple/data14.csv\")\n",
    "df15 = pd.read_csv(\"triple/data15.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUfNPzv3BZ-v"
   },
   "source": [
    "# Data Preparation: Cleaning Each Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ofJbK0vB9lr"
   },
   "source": [
    "Now that we have all DataFrames, it's time to inspect them to see if they need any cleaning. Let's look into the dataset one-by-one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIAkfywxOxk2",
    "outputId": "c07c8549-b217-4c01-8708-23fb83b3ef2f"
   },
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEjHqJj5BpQA",
    "outputId": "c1803330-6f3c-407f-e48e-6ba6653f9ff1"
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5YNs17JCN6q"
   },
   "source": [
    "The dataset has 4966 observations and 129 columns where 112 columns have float64 datatype, 16 columns have int64 datatype and 1 column has object datatype. Since info function does not let us see the each column description, we will take a look at the 15 observations of the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "2T-8FCvSBtEU",
    "outputId": "c26561f6-fff3-4867-f8a0-a36485278982"
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn-52TxvDi_X"
   },
   "source": [
    "Lets inspect other datasets to see the posibility of merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db9vjN04DFiq",
    "outputId": "33fe5a97-16a1-4fde-c47d-f1862ff81d68"
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CFTM4JjE7JF",
    "outputId": "7d037ee1-6d4c-44d9-db6c-e8a8cc7e3235"
   },
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsD0Q2I-E96c",
    "outputId": "648f4135-a0b0-49c0-d0d2-7fc7a6dbb14e"
   },
   "outputs": [],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pejnpbFvFFBv",
    "outputId": "76454fdb-fd3d-4aed-c92d-0de9a9fe028f"
   },
   "outputs": [],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DudoORbkFHT1",
    "outputId": "a015d0be-bc98-46ad-e961-f4523d08c4bb"
   },
   "outputs": [],
   "source": [
    "df6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYLiyRgDFI_D",
    "outputId": "15852f20-ee63-456f-e21d-aed6572bb778"
   },
   "outputs": [],
   "source": [
    "df7.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNWHCVvDFKpG",
    "outputId": "4ce883df-46a7-4a5c-8fa7-84d913d70880"
   },
   "outputs": [],
   "source": [
    "df8.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8jRnHvrFMw3",
    "outputId": "0d540cc0-9008-44db-cb35-5c7d9e44e90a"
   },
   "outputs": [],
   "source": [
    "df9.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXq-yHQLFOiJ",
    "outputId": "8e6038e8-e31b-4301-8884-8e571953e956"
   },
   "outputs": [],
   "source": [
    "df10.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spMyB7kaFRl9",
    "outputId": "2d897d68-6dce-4249-8afb-b04b7d2ab191"
   },
   "outputs": [],
   "source": [
    "df11.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dfdu9MRFTeR",
    "outputId": "4cb78a3d-7939-488f-afc9-de40af85ddb2"
   },
   "outputs": [],
   "source": [
    "df12.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orQM2bWPFVMS",
    "outputId": "b2c24831-b510-4208-a291-4337db7420e5"
   },
   "outputs": [],
   "source": [
    "df13.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLGcEXNUFXH9",
    "outputId": "6dd8c037-10f3-4b88-f667-99f7ce262e7c"
   },
   "outputs": [],
   "source": [
    "df14.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIJKEgwMFY5d",
    "outputId": "7239cffb-69d2-446f-8a99-c89572dd6dd0"
   },
   "outputs": [],
   "source": [
    "df15.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6c6RSyXFlb5"
   },
   "source": [
    "All the data have same number of features, therefore we can merge the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "R0aD9Cz2Favm",
    "outputId": "a2d75ef3-f837-4dd2-d550-a7434266c37a"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSl1_JRLGxgq"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNjMMgQLZUAu",
    "outputId": "744f49a8-176d-4b01-efd0-82a1d5dc1de2"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afOqQytJZY3B"
   },
   "source": [
    "According to https://sites.google.com/a/uah.edu/tommy-morris-uah/ics-data-sets?pli=1, the 129 colums are 29 types of measurements from each phasor measurement units (PMU). In the power system there are 4 PMUs which measure 29 features for 116 PMU measurement columns total. Each column is in the form of “R#-Signal Reference” that indicates a type of measurement from a PMU specified by “R#”. \n",
    "\n",
    "The \"marker\" column which contain a three class categorical data (NoEvent, Natural, and Attack) are the target features.\n",
    "\n",
    "Since the dataset is very large with 78,377 observations, this will affect the computational speed of our analysis and model building. A random sample will be selected from the dataset without altering the distribution of the target (marker). Therefore, we can count the three class marker and randomly select 30% of the dataset. So first we look at the summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "QeLsg43Uo6h6",
    "outputId": "1e1cd8c0-00ff-4c1c-c41e-63216c0f6bcb"
   },
   "outputs": [],
   "source": [
    "# Summary of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics of the dataset show varying weight of the features from high negative to high positive values. Several dataset has very low standard deviation. Let's see how balance the target variable is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMtdcOG7aN5w",
    "outputId": "9877b7ea-9514-4072-d750-5ba76aa4117f"
   },
   "outputs": [],
   "source": [
    "df['marker'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABnneUtcakSS"
   },
   "source": [
    "Let's check the percentage of each marker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C42rxI3eajZU",
    "outputId": "6b9dbe51-bce0-44ff-fb17-af0dbe72791f"
   },
   "outputs": [],
   "source": [
    "print(\"Percentage of Attack marker: \", round((df['marker'].value_counts()['Attack']/(sum(df['marker'].value_counts())))*100,2),\"%\")\n",
    "print(\"Percentage of Natural marker: \", round((df['marker'].value_counts()['Natural']/(sum(df['marker'].value_counts())))*100,2),\"%\")\n",
    "print(\"Percentage of NoEvents marker: \", round((df['marker'].value_counts()['NoEvents']/(sum(df['marker'].value_counts())))*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lO3Tr6g0bscE"
   },
   "source": [
    "Therefore our sample should approximately have similar percentage of the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "6WNGwmmWcOrB",
    "outputId": "de8ace33-0f17-4c43-b14a-8aef8633dda1"
   },
   "outputs": [],
   "source": [
    "new_df = df.sample(frac=0.3)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHy6g8U-eDIq"
   },
   "source": [
    "Let's check the new distribution of the sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the markers\n",
    "new_df['marker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VyaiFnnVeRYi",
    "outputId": "c9c434a9-3e7f-4a22-b88c-e7293e4aaa79"
   },
   "outputs": [],
   "source": [
    "# Computing the percentage of the target values\n",
    "print(\"Percentage of Attack marker: \", round((new_df['marker'].value_counts()['Attack']/(sum(new_df['marker'].value_counts())))*100,2),\"%\")\n",
    "print(\"Percentage of Natural marker: \", round((new_df['marker'].value_counts()['Natural']/(sum(new_df['marker'].value_counts())))*100,2),\"%\")\n",
    "print(\"Percentage of NoEvents marker: \", round((new_df['marker'].value_counts()['NoEvents']/(sum(new_df['marker'].value_counts())))*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObA8x7LeepmJ"
   },
   "source": [
    "Since the percentage is approximately similar to the original dataset, this means that the distribution is largely the same.\n",
    "\n",
    "Now, we can analyse the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdNZIWsdgyLB",
    "outputId": "558c5d31-5a79-45dd-b518-3416bd894725"
   },
   "outputs": [],
   "source": [
    "# Shape of sampled dataset\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eiXa1960Go-T",
    "outputId": "2b60b5e9-8d96-49ea-eba3-f9e5a6a21e8d"
   },
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "new_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwViS-UYC8mG"
   },
   "source": [
    "There are no null values in dataset, but let's take a look at what the numerical values of the dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "cBT4oh5TUDQU",
    "outputId": "a4ac11a4-5eea-4fbb-cab1-cee7bb15cee7"
   },
   "outputs": [],
   "source": [
    "# Summary of dataset\n",
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAnouf2sis8Y"
   },
   "source": [
    "Lets See how the features are related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "auhI7tESlWW8",
    "outputId": "34bff17d-40ab-4a56-d605-1a0930128234"
   },
   "outputs": [],
   "source": [
    "# Computing the correlation matrix of the explanatory features\n",
    "new_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix shows the correlation of some of the features as a NaN value.\n",
    "\n",
    "In this instance, the NaN is taken to mean that there is no relation between the two variables. The presence of nan values in the output may arise for a variety of reasons. In our case, when the standard deviation of one feature is zero, it generates a NaN value as dividing the covariance of the two feature with zero is mathematically incorrect.\n",
    "\n",
    "Therefore, we will drop all columns with 0 standard deviation as it does not add any importance when predicting on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with 0 sstandard deviation.\n",
    "stds = pd.DataFrame(new_df.describe().loc['std']).T\n",
    "\n",
    "cols = []\n",
    "for column in stds.columns:\n",
    "    if stds[column].item() == 0.0:\n",
    "        cols.append(column)\n",
    "        new_df.drop(column, inplace=True, axis=1)\n",
    "print('The columns dropped are: ', cols)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the correlation on the heatmap, we do it in batches as the screen is too small to accommodate the large feature correlation matrix. Since we have 125 columns, we divide the visualization into 5 batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "id": "mrBoMSEXUSHs",
    "outputId": "e3de87b0-8c6c-4018-a6a0-43f24e3afa2b"
   },
   "outputs": [],
   "source": [
    "# Visualizing correlation matrix of first 25 columns of the dataset on a heatmap\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(new_df.iloc[:, 0:25].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing correlation matrix of first 25 columns of the dataset on a heatmap\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(new_df.iloc[:, 25:50].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing correlation matrix of first 25 columns of the dataset on a heatmap\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(new_df.iloc[:, 50:75].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing correlation matrix of first 25 columns of the dataset on a heatmap\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(new_df.iloc[:, 75:100].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing correlation matrix of first 25 columns of the dataset on a heatmap\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(new_df.iloc[:, 100:125].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmaps for all the batches shows that several columns have high correlation. As high as 0.97 for some and this is not good for the dataset as it is just extra noise in the dataset. If two variables are correlated, we can predict one from the other. Therefore, if two features are correlated, the model only really needs one of them, as the second one does not add additional information. We need to set an absolute value threshold for selecting the variables. If we find that the predictor variables are correlated among themselves, we can drop the variable which has a lower correlation coefficient value with the target variable. This is done in the feature Engineering section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Analysis of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform a univariate analysis on the dataset to observe how each feature is dristributed. \n",
    "\n",
    "The first trial of building a histogram, we observe that the dataset contains infinite values that pandas read as a floating value. therefore, let's handle the infinite values to allow us properly visualise the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isinf(new_df.iloc[:,:-1]).values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of infinite values are too large that we cannot drop them as it might distort the dataset. So we will replace the infinite values with the mean of the each feature containing the infinite values. First we will replace the values with Null values then with the mean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing infinite values with NaN\n",
    "new_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Checking if infinite values have been replaced to null values\n",
    "new_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply imputer to the dataset to input the mean value.\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "new_df.loc[:, new_df.columns != \"marker\"] = imputer.fit_transform(new_df.loc[:, new_df.columns != \"marker\"])\n",
    "\n",
    "new_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the distribution of some of the features using a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "nI1FQTPsDK9y",
    "outputId": "ec7e3b62-9289-4c96-90f2-182fcec7e440"
   },
   "outputs": [],
   "source": [
    "# Visualizing ficolumns of the dataset\n",
    "new_df.iloc[:, 0:30].hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.iloc[:, 30:60].hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several features in the dataset are very densed and with very low variance. These features tend to contribute less to the prediction of the target variable. Therefore it will be handled during the feature engineering of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we investigate the relationship between some explanatory variable and the target variable. Creating a grouped bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_G8UdMGyJjNR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grouped boxplot chart\n",
    "rows=22\n",
    "cols=6\n",
    "fig = plt.figure(figsize=(30,60))\n",
    "for i in range(0, len(new_df.columns) - 1):\n",
    "    cat = \"marker\"\n",
    "    num = new_df.columns[i]\n",
    "    ax=fig.add_subplot(rows, cols, i+1)\n",
    "    sns.boxplot(x = cat, y = num, data=new_df, palette='GnBu', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each box shows how spread out the data is within group and putting boxes side by side indicates the difference among groups. It is aligned with ANOVA test which also analyze the degree of variance between-group compared to within-group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by checking for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped boxplot chart\n",
    "rows=22\n",
    "cols=6\n",
    "df_cols = new_df.columns[0:57]\n",
    "fig = plt.figure(figsize=(30,60))\n",
    "for i, col in enumerate(df_cols):\n",
    "    ax=fig.add_subplot(rows, cols, i+1)\n",
    "    sns.boxplot(x=new_df[col], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the exploratory data analysis, we discovered that there were only \"infinity\" as missing values in the dataset and we handled that to be able to visualize the dataset. Also the boxplots shows a lot of outliers. Dropping or trimm the outliers will cause the removal of a large number of records from your dataset which isn’t desirable. Therefore we are going to cap the dataset to minimize the outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = new_df.iloc[:,0:new_df.shape[1]].mean() + 3*new_df.iloc[:,0:new_df.shape[1]].std()\n",
    "lower_limit = new_df.iloc[:,0:new_df.shape[1]].mean() - 3*new_df.iloc[:,0:new_df.shape[1]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.iloc[:,0:new_df.shape[1]-1] = np.where(new_df.iloc[:,0:new_df.shape[1]-1] > upper_limit,upper_limit,\n",
    "                      np.where(new_df.iloc[:,0:new_df.shape[1]-1] < lower_limit,lower_limit,\n",
    "                      new_df.iloc[:,0:new_df.shape[1]-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grouped boxplot chart\n",
    "rows=22\n",
    "cols=6\n",
    "df_cols = new_df.columns[0:-1]\n",
    "fig = plt.figure(figsize=(30,60))\n",
    "for i, col in enumerate(df_cols):\n",
    "    ax=fig.add_subplot(rows, cols, i+1)\n",
    "    sns.boxplot(x=new_df[col], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the outliers are not displaced, but they have been minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare feature vector and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explanatory varables consists of remaining 57%, while marker is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature vector\n",
    "X = new_df.drop(['marker'], axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = new_df['marker'].reset_index(drop=True)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding target variable\n",
    "Encoder=LabelEncoder()\n",
    "y=Encoder.fit_transform(y)\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the complexity of the feature vector and the vast difference in the variance, we scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data to attain internal consistency\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(X)\n",
    "X = scalar.transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model  creation  and  evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sckit-learn library, three models (Random Forest, Logistics Regression, and K Nearest Neighborhood) are constructed with 10-fold cv and are compared. The metrics to be used in the comparison will be as follows:\n",
    "\n",
    "Due to a high class imbalance (Percentage of Attack marker:  71.2%, Percentage of Natural marker:  23.45%, Percentage of NoEvents marker:  5.35%), a weighted recall, precision and f1 score (which considers both precision and recall) will be used in evaluating the model. the weighted metric, accounts for class imbalance by computing the average of binary metrics weighted by the number of samples of each class in the target.\n",
    "\n",
    "https://towardsdatascience.com/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "rf_cv = RandomForestClassifier()\n",
    "\n",
    "# evaluate the model\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Using crossvalidation of 10 splits to evaluate f1 value\n",
    "scores = cross_validate(rf_cv, X, y, cv=cv, scoring=['precision_weighted', 'recall_weighted', 'f1_weighted'])\n",
    "\n",
    "print('Precision value for the cross validation of Random Forest classifier is: ', np.mean(scores['test_precision_weighted']) , '\\n')\n",
    "print('Recall value for the cross validation of Random Forest classifier is: ', np.mean(scores['test_recall_weighted']) , '\\n')\n",
    "print('F1 value for the cross validation of Random Forest classifier is: ', np.mean(scores['test_f1_weighted']) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "lg_cv = LogisticRegression()\n",
    "\n",
    "# evaluate the model\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Using crossvalidation of 10 splits to evaluate f1 value\n",
    "scores1 = cross_validate(lg_cv, X, y, cv=cv, scoring=['precision_weighted', 'recall_weighted', 'f1_weighted'])\n",
    "\n",
    "print('Precision value for the cross validation of Logistic Regression is: ', np.mean(scores1['test_precision_weighted']) , '\\n')\n",
    "print('Recall value for the cross validation of Logistic Regression is: ', np.mean(scores1['test_recall_weighted']) , '\\n')\n",
    "print('F1 value for the cross validation of Logistic Regression is: ', np.mean(scores1['test_f1_weighted']) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "knn_cv = KNeighborsClassifier()\n",
    "\n",
    "# evaluate the model\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Using crossvalidation of 10 splits to evaluate f1 value\n",
    "scores2 = cross_validate(knn_cv, X, y, cv=cv, scoring=['precision_weighted', 'recall_weighted', 'f1_weighted'])\n",
    "\n",
    "print('Precision value for the cross validation of KNeighbors Classifier is: ', np.mean(scores2['test_precision_weighted']) , '\\n')\n",
    "print('Recall value for the cross validation of KNeighbors Classifier is: ', np.mean(scores2['test_recall_weighted']) , '\\n')\n",
    "print('F1 value for the cross validation of KNeighbors Classifier is: ', np.mean(scores2['test_f1_weighted']) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Visualize the performance of the models according to the k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see what the accuracy looked like during the crossvalidation process\n",
    "plt.figure(figsize=(10,5))\n",
    "num_k = range(10)\n",
    "\n",
    "plt.plot(num_k, scores['test_precision_weighted'], label='Random Forest')\n",
    "plt.plot(num_k, scores1['test_precision_weighted'], label='Logistics Regression')\n",
    "plt.plot(num_k, scores2['test_precision_weighted'], label='K Nearest Neighborhood')\n",
    "plt.legend(bbox_to_anchor = (1,1.3))\n",
    "plt.title('Weighted Precision Scores of the Three Models')\n",
    "plt.xlabel('Number of validations')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see what the accuracy looked like during the crossvalidation process\n",
    "plt.figure(figsize=(10,5))\n",
    "num_k = range(10)\n",
    "\n",
    "plt.plot(num_k, scores['test_f1_weighted'], label='Random Forest')\n",
    "plt.plot(num_k, scores1['test_f1_weighted'], label='Logistics Regression')\n",
    "plt.plot(num_k, scores2['test_f1_weighted'], label='K Nearest Neighborhood')\n",
    "plt.legend(bbox_to_anchor = (1,1.3))\n",
    "plt.title('Weighted Recall Scores of the Three Models')\n",
    "plt.xlabel('Number of validations')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see what the accuracy looked like during the crossvalidation process\n",
    "plt.figure(figsize=(10,5))\n",
    "num_k = range(10)\n",
    "\n",
    "plt.plot(num_k, scores['test_recall_weighted'], label='Random Forest')\n",
    "plt.plot(num_k, scores1['test_recall_weighted'], label='Logistics Regression')\n",
    "plt.plot(num_k, scores2['test_recall_weighted'], label='K Nearest Neighborhood')\n",
    "plt.legend(bbox_to_anchor = (1,1.3))\n",
    "plt.title('Weighted Recall Scores of the Three Models')\n",
    "plt.xlabel('Number of validations')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three evaluation metrics shows that Random Forest classification performed better than the the other two models, followed by K Nearest Neighborhood and then the Logistics Regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During exploratory data analysis, we discovered that several features are highly correlated. therefore, we first drop one of such features that have correlation < -0.9 and > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select upper traingle of correlation matrix\n",
    "corr_matrix = new_df.corr()\n",
    "upper = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))).abs()\n",
    "print(upper)\n",
    "\n",
    "# Find index of columns with correlation greater than 0.90\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "print(to_drop)\n",
    "\n",
    "# drop the columns\n",
    "new_df = new_df.drop(columns=to_drop, axis=1)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the number of features left, we will use mutual information gain to further select impoortant features. Mutual information from the field of information theory is the application of information gain (typically used in the construction of decision trees) to feature selection.\n",
    "\n",
    "Mutual information is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable. A threshold of 0.01 is given for the selection.\n",
    "\n",
    "https://machinelearningmastery.com/feature-selection-with-numerical-input-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of most relevant features\n",
    "new_df = new_df.drop(['marker'], axis=1)\n",
    "high_score_features = []\n",
    "feature_scores = mutual_info_classif(new_df, y, random_state=0)\n",
    "for score, f_name in sorted(zip(feature_scores, new_df.columns), reverse=True):\n",
    "        if score <= 0.01:\n",
    "                high_score_features.append(f_name)\n",
    "                print(f_name, score)\n",
    "\n",
    "#Representing in list form\n",
    "mutual_info = pd.Series(feature_scores)\n",
    "mutual_info.index = new_df.columns[0:58]\n",
    "\n",
    "#plot the ordered mutual_info values per feature\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_X = new_df[high_score_features]\n",
    "selected_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuilding model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale the features since the initial X was not used to select best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data to attain internal consistency\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(selected_X)\n",
    "selected_X = scalar.transform(selected_X)\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "rf_cv = RandomForestClassifier()\n",
    "\n",
    "# evaluate the model\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Using crossvalidation of 10 splits to evaluate f1 value\n",
    "scores0 = cross_validate(rf_cv, selected_X, y, cv=cv, scoring=['precision_weighted', 'recall_weighted', 'f1_weighted'])\n",
    "\n",
    "print('Precision value for the cross validation of Random Forest classifier with selected feature is: ', np.mean(scores0['test_precision_weighted']) , '\\n')\n",
    "print('Recall value for the cross validation of Random Forest classifier with selected feature is: ', np.mean(scores0['test_recall_weighted']) , '\\n')\n",
    "print('F1 value for the cross validation of Random Forest classifier with selected feature is: ', np.mean(scores0['test_f1_weighted']) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "lg_cv = LogisticRegression()\n",
    "\n",
    "# evaluate the model\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Using crossvalidation of 10 splits to evaluate f1 value\n",
    "scores10 = cross_validate(lg_cv, selected_X, y, cv=cv, scoring=['precision_weighted', 'recall_weighted', 'f1_weighted'])\n",
    "\n",
    "print('Precision value for the cross validation of Logistic Regression with selected feature is: ', np.mean(scores10['test_precision_weighted']) , '\\n')\n",
    "print('Recall value for the cross validation of Logistic Regression with selected feature is: ', np.mean(scores10['test_recall_weighted']) , '\\n')\n",
    "print('F1 value for the cross validation of Logistic Regression with selected feature is: ', np.mean(scores10['test_f1_weighted']) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "knn_cv = KNeighborsClassifier()\n",
    "\n",
    "# evaluate the model\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Using crossvalidation of 10 splits to evaluate f1 value\n",
    "scores20 = cross_validate(knn_cv, selected_X, y, cv=cv, scoring=['precision_weighted', 'recall_weighted', 'f1_weighted'])\n",
    "\n",
    "print('Precision value for the cross validation of KNeighbors Classifier with selected feature is: ', np.mean(scores20['test_precision_weighted']) , '\\n')\n",
    "print('Recall value for the cross validation of KNeighbors Classifier with selected feature is: ', np.mean(scores20['test_recall_weighted']) , '\\n')\n",
    "print('F1 value for the cross validation of KNeighbors Classifier with selected feature is: ', np.mean(scores20['test_f1_weighted']) , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the model rebuilt with the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see what the accuracy looked like during the crossvalidation process\n",
    "plt.figure(figsize=(10,5))\n",
    "num_k = range(10)\n",
    "\n",
    "plt.plot(num_k, scores0['test_precision_weighted'], label='Random Forest')\n",
    "plt.plot(num_k, scores10['test_precision_weighted'], label='Logistics Regression')\n",
    "plt.plot(num_k, scores20['test_precision_weighted'], label='K Nearest Neighborhood')\n",
    "plt.legend(bbox_to_anchor = (1,1.3))\n",
    "plt.title('Weighted Precision Scores of the Three Models')\n",
    "plt.xlabel('Number of validations')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see what the accuracy looked like during the crossvalidation process\n",
    "plt.figure(figsize=(10,5))\n",
    "num_k = range(10)\n",
    "\n",
    "plt.plot(num_k, scores0['test_recall_weighted'], label='Random Forest')\n",
    "plt.plot(num_k, scores10['test_recall_weighted'], label='Logistics Regression')\n",
    "plt.plot(num_k, scores20['test_recall_weighted'], label='K Nearest Neighborhood')\n",
    "plt.legend(bbox_to_anchor = (1,1.3))\n",
    "plt.title('Weighted Recall Scores of the Three Models')\n",
    "plt.xlabel('Number of validations')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see what the accuracy looked like during the crossvalidation process\n",
    "plt.figure(figsize=(10,5))\n",
    "num_k = range(10)\n",
    "\n",
    "plt.plot(num_k, scores0['test_f1_weighted'], label='Random Forest')\n",
    "plt.plot(num_k, scores10['test_f1_weighted'], label='Logistics Regression')\n",
    "plt.plot(num_k, scores20['test_f1_weighted'], label='K Nearest Neighborhood')\n",
    "plt.legend(bbox_to_anchor = (1,1.3))\n",
    "plt.title('Weighted Recall Scores of the Three Models')\n",
    "plt.xlabel('Number of validations')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is observed that the performance of the Random Forest classifier reduced when the features were reduced. Although on a average, it is still the best model in the set, but the other two models performed almost the same as well. These performances shows that some percentage of importance from the features was lost, but the noise was reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From observation, the best performing model is the Random Forest that used all the features in the dataset. Therefore to get a good parameter for the model, me check on the n_estimators and max_depth of the Random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10)\n",
    "CV_rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using best parameters to rebuild model\n",
    "rfc1=RandomForestClassifier(random_state=42, n_estimators= 500, max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit new model\n",
    "rfc1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction and evaluation\n",
    "y_pred=rfc1.predict(X)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = {'Random Forest without tuning':{'precision':0.86,'Recall':0.86,'F1_score':0.85},\\\n",
    "            'Random Forest with tuning':{'precision':0.78,'Recall':0.75,'F1_score':0.68},\\\n",
    "            }\n",
    "\n",
    "cv_acc = [[0.85, 0.85, 0.84],[0.75 , 0.73, 0.65]]\n",
    "columns = ['Precision', 'Recall', 'F1_score']\n",
    "rows = ['Random Forest without tuning', 'Random Forest with tuning']\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "pd.DataFrame(cv_data).plot(kind='bar', figsize=(14,6))\n",
    "table = plt.table(cellText=cv_acc, rowLabels=rows, colLabels=columns)\n",
    "\n",
    "# make space for the table:\n",
    "plt.subplots_adjust(left=0.2, bottom=0.2)\n",
    "plt.ylabel(\"Accuracy Value\".format(200))\n",
    "plt.legend(bbox_to_anchor = (1,1.3))\n",
    "plt.xticks([])\n",
    "plt.title('Accuracy of Random Forest, with and without tunning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar plot shows that the default parameters of the dataset performed better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0946b56fa3c730f9cd8031d6e63b4bd515f19aeec22013b3dd189a3099df804"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
